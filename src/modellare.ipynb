{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms.functional as TF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tecniche di modellazione per l'apprendimento automatico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La discesa del gradiente e la rete neurale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tecniche per la modellazione di immagini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pillow\n",
    "from PIL import Image\n",
    "# open the image file for reading\n",
    "img = Image.open('../res/me.jpg')\n",
    "img = img.crop((0, 0, 1024, 1024))\n",
    "img = img.resize((512, 512))\n",
    "import numpy as np\n",
    "img_array = np.array(img)\n",
    "\n",
    "# convert the numpy array to a PIL image\n",
    "img_pil = Image.fromarray(img_array)\n",
    "\n",
    "# display the image in the notebook\n",
    "display(img_pil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the size of the image\n",
    "print(img_array.shape)\n",
    "# convert the numpy array to a pytorch tensor\n",
    "img_tensor = TF.to_tensor(img_array).unsqueeze(0)\n",
    "print(img_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a filter with convolutional layers\n",
    "filter1 = nn.Conv2d(\n",
    "    in_channels=3,\n",
    "    out_channels=1, \n",
    "    kernel_size=5,\n",
    "    padding=2,\n",
    ")\n",
    "print(img_tensor.shape)\n",
    "\n",
    "# apply filter 1 to the image\n",
    "img_tensor_filter1 = filter1(img_tensor)\n",
    "print(img_tensor_filter1.shape)\n",
    "\n",
    "# display the filtered image\n",
    "img_filter1 = TF.to_pil_image(img_tensor_filter1.squeeze(0))\n",
    "display(img_filter1)\n",
    "\n",
    "# define a reduce filter to reduce the image\n",
    "reduce1 = nn.MaxPool2d(\n",
    "    kernel_size=(4, 4),\n",
    ")\n",
    "\n",
    "# apply the reduce filter to the image\n",
    "print(img_tensor_filter1.shape)\n",
    "img_tensor_reduce1 = reduce1(img_tensor_filter1)\n",
    "print(img_tensor_reduce1.shape)\n",
    "\n",
    "# display the reduced image\n",
    "img_reduce1 = TF.to_pil_image(img_tensor_reduce1.squeeze(0))\n",
    "display(img_reduce1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
